{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7b5292",
   "metadata": {},
   "source": [
    "## 1.Tìm hiểu về đề tài:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003729f",
   "metadata": {},
   "source": [
    "### 1.1. Giới thiệu về đề tài:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc356f45",
   "metadata": {},
   "source": [
    "- **Tên cuộc thi:** Recruit Restaurant Visitor Forecasting\n",
    "- **Mô tả:** \n",
    "    - Việc dự đoán sẽ dựa vào các thông tin về vị trí (kinh độ, vĩ độ) của nhà hàng, các ngày lễ trong năm, thông tin dự báo thời tiết ngày hôm đó và dữ liệu đặt chỗ thông qua trang web đặt chỗ của nhà hàng và dữ liệu khách đã đến trong cơ sở dữ liệu của nhà hàng.\n",
    "    - **Output:** số lượng khách đến nhà hàng\n",
    "- **Link kaggle:** https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3974fcd",
   "metadata": {},
   "source": [
    "### 1.2. Lí do chọn đề tài"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d330d6",
   "metadata": {},
   "source": [
    "Trong bối cảnh chuyển đổi số diễn ra mạnh mẽ, việc ứng dụng khoa học dữ liệu và học máy (Machine Learning) vào các bài toán thực tế ngày càng trở nên quan trọng, đặc biệt trong lĩnh vực kinh doanh và dịch vụ. Một trong những bài toán có giá trị ứng dụng cao là dự báo nhu cầu khách hàng, giúp doanh nghiệp tối ưu vận hành và nâng cao hiệu quả kinh doanh.\n",
    "\n",
    "Cuộc thi “Recruit Restaurant Visitor Forecasting” trên nền tảng Kaggle đặt ra bài toán dự đoán số lượng khách ghé thăm nhà hàng trong tương lai dựa trên dữ liệu lịch sử về lượt khách, đặt chỗ, thông tin nhà hàng và lịch ngày lễ. Đây là một bài toán dự báo chuỗi thời gian (Time Series Forecasting) mang tính thực tiễn cao, phản ánh đúng các thách thức mà doanh nghiệp trong ngành nhà hàng – dịch vụ đang phải đối mặt.\n",
    "\n",
    "Đề tài được lựa chọn vì những lý do sau:\n",
    "\n",
    "Thứ nhất, tính ứng dụng thực tế cao.\n",
    "Việc dự đoán chính xác số lượng khách giúp nhà hàng chủ động trong việc chuẩn bị nguyên vật liệu, bố trí nhân sự, giảm thiểu lãng phí và nâng cao chất lượng phục vụ. Do đó, kết quả của bài toán không chỉ mang ý nghĩa học thuật mà còn có thể áp dụng trực tiếp vào hoạt động kinh doanh thực tế.\n",
    "\n",
    "Thứ hai, phù hợp để nghiên cứu và thực hành các kỹ thuật học máy hiện đại.\n",
    "Bài toán yêu cầu xử lý dữ liệu theo thời gian, khai thác các yếu tố như ngày trong tuần, ngày lễ, xu hướng theo mùa và hành vi đặt chỗ của khách hàng. Điều này tạo điều kiện để áp dụng các kỹ thuật quan trọng như:\n",
    "\n",
    "Phân tích và xử lý chuỗi thời gian\n",
    "\n",
    "Feature engineering từ dữ liệu thực tế\n",
    "\n",
    "So sánh và đánh giá các mô hình dự báo\n",
    "\n",
    "Qua đó giúp người học củng cố kiến thức lý thuyết và nâng cao kỹ năng triển khai mô hình.\n",
    "\n",
    "Thứ ba, dữ liệu phong phú, đa nguồn và gần với dữ liệu thực tế.\n",
    "Dataset của cuộc thi bao gồm nhiều bảng dữ liệu khác nhau như thông tin nhà hàng, lịch sử khách ghé thăm, dữ liệu đặt chỗ và lịch ngày lễ. Việc kết hợp các nguồn dữ liệu này phản ánh đúng đặc trưng của các bài toán dữ liệu trong thực tế, giúp rèn luyện khả năng tiền xử lý, làm sạch và tích hợp dữ liệu.\n",
    "\n",
    "Thứ tư, phù hợp với định hướng học tập và nghiên cứu trong lĩnh vực Khoa học dữ liệu.\n",
    "Đề tài cho phép mở rộng theo nhiều hướng như so sánh các mô hình dự báo, cải tiến đặc trưng đầu vào hoặc đánh giá tác động của các yếu tố bên ngoài đến lượng khách. Điều này rất phù hợp để phát triển thành đồ án môn học, đồ án tốt nghiệp hoặc dự án cá nhân nhằm xây dựng portfolio.\n",
    "\n",
    "Từ những lý do trên, đề tài “Dự báo số lượng khách nhà hàng – Recruit Restaurant Visitor Forecasting” được lựa chọn nhằm kết hợp giữa lý thuyết và thực tiễn, đồng thời nâng cao năng lực phân tích dữ liệu và xây dựng mô hình học máy cho các bài toán dự báo trong đời sống thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23691e7a",
   "metadata": {},
   "source": [
    "## Ý tưởng để giải quyết bài toán:\n",
    "- Giải quyết về vấn đề dữ liệu:\n",
    "    - Dữ liệu cửa hàng\n",
    "        - Số lượng khách hàng đến cửa hàng trong quá khứ: `air_visit_data.csv`\n",
    "        - Thời gian trong dataset:  `date_info.csv`\n",
    "        - Thông tin cửa hàng đính kèm với với trạm thời tiết gần đó: `air_store_info`\n",
    "        - chuẩn bị tập test `submission.csv`\n",
    "    - Dữ liệu thời tiết\n",
    "        - Dữ liệu thời tiết của 1663 trạm\n",
    "- Tiền xử lí dữ liệu\n",
    "    - Xử lí giá trị ngoại lai\n",
    "    - Tính trọng số theo cấp số nhân cho số lượng khác hàng, cùng với một số đặc trưng khác\n",
    "- Huấn luyện mô hình\n",
    "    - Mã hóa dữ liệu\n",
    "    - Chia dữ liệu train, test\n",
    "    - Huấn luyện mô hình\n",
    "    - Hiển thị kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d291ccd",
   "metadata": {},
   "source": [
    "## 2. Giải quyết vấn đề"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adbe8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6366fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8817600",
   "metadata": {},
   "source": [
    "### 2.1. Dữ liệu nhà hàng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72f64b",
   "metadata": {},
   "source": [
    "#### 2.1.1. File `air_visit_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a55c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252108 entries, 0 to 252107\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   air_store_id  252108 non-null  object\n",
      " 1   visit_date    252108 non-null  object\n",
      " 2   visitors      252108 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "path1 = 'data/air_visit_data.csv'\n",
    "air_visit = pd.read_csv(path1)\n",
    "air_visit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e4615",
   "metadata": {},
   "source": [
    "- Thông qua việc đọc dữ liệu ta thấy rằng: file chứ các cột `air_store_id`, `visit_date`, `visitors`\n",
    "- Ý nghĩa của các cột dữ liệu: \n",
    "    - **Với cột dữ liệu `air_store_id`:**\n",
    "        - Đây là cột dữ liệu cung cấp id của cửa hàng, là một dãy kí tự có độ dài 20\n",
    "        - Trạng thái: cột chứa 252108 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: `air_store_id` có kiểu dữ liệu là object\n",
    "    - **Với cột dữ liệu `visit_date`:**\n",
    "        - Đây là cột dữ liệu chứa thời gian có khách của cửa hàng, chứa ngày tháng năm\n",
    "        - Trạng thái: cột chứa 252108 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: `visit_date` có kiểu dữ liệu là object\n",
    "    - **Với cột dữ liệu `visitors`:**\n",
    "        - Đây là cột dữ liệu mà nhóm phải dự đoán để đưa ra kết quả, là các số nguyên dương\n",
    "        - Trang thái: cột chứa 252180 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: `visitors` có kiểu dữ liệu là int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7506f022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25\n",
       "1  air_ba937bf13d40fb24  2016-01-14        32\n",
       "2  air_ba937bf13d40fb24  2016-01-15        29\n",
       "3  air_ba937bf13d40fb24  2016-01-16        22\n",
       "4  air_ba937bf13d40fb24  2016-01-18         6\n",
       "5  air_ba937bf13d40fb24  2016-01-19         9\n",
       "6  air_ba937bf13d40fb24  2016-01-20        31\n",
       "7  air_ba937bf13d40fb24  2016-01-21        21\n",
       "8  air_ba937bf13d40fb24  2016-01-22        18\n",
       "9  air_ba937bf13d40fb24  2016-01-23        26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae94c3f",
   "metadata": {},
   "source": [
    "- **Ý tưởng để xử lí file `visit_data.csv`:** \n",
    "    - Chuyển dữ liệu `visit_date` kiểu object sang kiểu thời gian chuẩn: nhóm sử dụng to_datetime() để làm việc đó\n",
    "    - Làm liền mạch chuỗi dữ liệu thời gian: ở bảng dữ liệu phía trên, chúng ta có thể thấy rằng dữ liệu chỉ hiển thị những ngày có khách, vì vậy nhóm đã phải dùng lệnh `resample('1d')` để có thể tạo ra một chuỗi dữ liệu thời gian liên tục, các ngày thiểu - không có khách vẫn được thêm vào\n",
    "    - Định dạng thời gian theo kiểu YYYY-mm-dd: bằng dt.strftime(%Y-%m-%d)\n",
    "    - Thay dữ liệu trống: Vốn dĩ những ngày được thêm vào đều không có giá trị, nên nhóm quyết định thay thế bằng 0\n",
    "    - Thêm nhãn nhận biết: nhóm đã thêm nhãn `was_nil`. Với giá trị `False` thì ta biết được đó là dữ liệu của hệ thống, còn với giá trị `True` thì là dữ liệu do chúng ta thêm vào\n",
    "- **Output:** cung cấp cho ta một file với dữ liệu thời gian liền mạch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ea53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_visit.index = pd.to_datetime(air_visit['visit_date'])\n",
    "air_visit = air_visit.groupby('air_store_id').apply(lambda data: data['visitors'].resample('1d').sum(), include_groups=False).reset_index()\n",
    "air_visit['visit_date'] = air_visit['visit_date'].dt.strftime('%Y-%m-%d') #chuyen dang YYYY-mm-dd\n",
    "air_visit.replace(0, np.nan, inplace=True)\n",
    "air_visit['was_nil'] = air_visit['visitors'].isnull()\n",
    "air_visit.fillna({'visitors': 0}, inplace = True) #ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341ee1b",
   "metadata": {},
   "source": [
    "Dữ liệu file `air_visit_data.csv` sau khi xử lí là:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c407eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-06</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-07</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-08</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  was_nil\n",
       "0  air_00a91d42b08b08d9  2016-07-01      35.0    False\n",
       "1  air_00a91d42b08b08d9  2016-07-02       9.0    False\n",
       "2  air_00a91d42b08b08d9  2016-07-03       0.0     True\n",
       "3  air_00a91d42b08b08d9  2016-07-04      20.0    False\n",
       "4  air_00a91d42b08b08d9  2016-07-05      25.0    False\n",
       "5  air_00a91d42b08b08d9  2016-07-06      29.0    False\n",
       "6  air_00a91d42b08b08d9  2016-07-07      34.0    False\n",
       "7  air_00a91d42b08b08d9  2016-07-08      42.0    False\n",
       "8  air_00a91d42b08b08d9  2016-07-09      11.0    False\n",
       "9  air_00a91d42b08b08d9  2016-07-10       0.0     True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "air_visit.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75c6f9",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8b3fb",
   "metadata": {},
   "source": [
    "#### 2.1.2 `File date_info.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d93ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   calendar_date  517 non-null    object\n",
      " 1   day_of_week    517 non-null    object\n",
      " 2   holiday_flg    517 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "date_info = pd.read_csv('data/date_info.csv')\n",
    "date_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f350ba6",
   "metadata": {},
   "source": [
    "- Thông qua việc xem dữ liệu file `date_info.csv` gồm 3 cột `calendar_date`, `day_of_week` và `holiday_flag`\n",
    "- Ý nghĩa của các cột dữ liệu: \n",
    "    - **Với cột dữ liệu `calendar_date`:**\n",
    "        - Đây là cột dữ liệu cung cấp thời gian \n",
    "        - Trạng thái: cột chứa 517 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: `calendar_date` có kiểu dữ liệu là object\n",
    "    - **Với cột dữ liệu `day_of_week`:**\n",
    "        - Đây là cột dữ liệu cung cấp cho chúng ta các thứ trong tuần\n",
    "        - Trạng thái: cột chứa 517 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: `day_of_week` có kiểu dữ liệu là object\n",
    "    - **Với cột dữ liệu `holiday_flg`:**\n",
    "        - Đây là cột dữ liệu cung cấp nhãn về ngày đó có phải là ngày lễ hay không. Với giá trị là 1 thì đây là ngày lễ, ngược lại giá trị 0 thì không phải là ngày lễ\n",
    "        - Trạng thái: cột chứa 517 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: `holiday_flg` có kiểu dữ liệu là int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae55737b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  calendar_date day_of_week  holiday_flg\n",
       "0    2016-01-01      Friday            1\n",
       "1    2016-01-02    Saturday            1\n",
       "2    2016-01-03      Sunday            1\n",
       "3    2016-01-04      Monday            0\n",
       "4    2016-01-05     Tuesday            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c6304",
   "metadata": {},
   "source": [
    "- **Ý tưởng để xử lí file date_info.csv:**\n",
    "    - Đổi tên 2 cột `calendar_date` và `holiday_flg` thành `visit_date` và `is_holiday` để có thể tiện dùng\n",
    "    - Tạo thêm 2 cột mới: nhóm tạo thêm `prev_holiday` và `after_holiday` để xét ngày trước và sau của ngày đang xét là ngày lễ, giá trị của 2 cột đều giống với cột `is_holiday`\n",
    "- **Ouput:** ta sẽ được file với dữ liệu cho biết rằng ngày đó có trong kì nghỉ dài hạn hay không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096e769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_info.rename(columns = {'calendar_date' : 'visit_date', 'holiday_flg' : 'is_holiday'}, inplace = True)\n",
    "date_info['prev_holiday'] = date_info['is_holiday'].shift().fillna(0)\n",
    "date_info['after_holiday'] = date_info['is_holiday'].shift(-1).fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e292f69",
   "metadata": {},
   "source": [
    "Đây là file `date_info.csv` sau khi được xử lí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e12024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date day_of_week  is_holiday  prev_holiday  after_holiday\n",
       "0  2016-01-01      Friday           1           0.0            1.0\n",
       "1  2016-01-02    Saturday           1           1.0            1.0\n",
       "2  2016-01-03      Sunday           1           1.0            0.0\n",
       "3  2016-01-04      Monday           0           1.0            0.0\n",
       "4  2016-01-05     Tuesday           0           0.0            0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556918c",
   "metadata": {},
   "source": [
    "#### 2.1.3 `File air_store_info.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b7185",
   "metadata": {},
   "source": [
    "Với file `air_store_info.csv`, nhóm đã sử dụng bảng đã được file đã được tiền xử lí sẵn nằm trong file dữ liệu thời tiết, lí do lựa chọn là vì file có sẵn dữ liệu trạm thời tiết trong đó, rất tiện cho việc join bảng sau này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7a774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 829 entries, 0 to 828\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   air_store_id          829 non-null    object \n",
      " 1   air_genre_name        829 non-null    object \n",
      " 2   air_area_name         829 non-null    object \n",
      " 3   latitude              829 non-null    float64\n",
      " 4   longitude             829 non-null    float64\n",
      " 5   latitude_str          829 non-null    object \n",
      " 6   longitude_str         829 non-null    object \n",
      " 7   station_id            829 non-null    object \n",
      " 8   station_latitude      829 non-null    float64\n",
      " 9   station_longitude     829 non-null    float64\n",
      " 10  station_vincenty      829 non-null    float64\n",
      " 11  station_great_circle  829 non-null    float64\n",
      "dtypes: float64(6), object(6)\n",
      "memory usage: 77.8+ KB\n"
     ]
    }
   ],
   "source": [
    "path3 = 'weather/air_store_info_with_nearest_active_station.csv'\n",
    "air_store_info = pd.read_csv(path3)\n",
    "air_store_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324b625",
   "metadata": {},
   "source": [
    "- Thông qua việc đọc file `air_store_info_with_nearest_active_station.csv`, ta thấy được file có 11 cột như sau `air_store_id`, `air_genre_name`, `air_area_name`, `latitude`, `longitude`, `latitude_str`, `longitude_str`, `station_id`, `station_latitude`, `station_longitude`, `station_vincenty`, `station_great_circle`\n",
    "- Ý nghĩa của các cột dữ liệu:\n",
    "    - Với các cột `air_genre_name`, `air_area_name`:\n",
    "        - Đây là các cột dữ liệu thể hiện loại hình, địa điểm của các nhà hàng\n",
    "        - Trạng thái: các cột có 829 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: đều mang kiểu dữ liệu object\n",
    "    - Với các cột `latitude`, `longitude`, `station_latitude`, `station_longitude`, `station_vincenty` và `station_great_circle`:\n",
    "        - Đây là các cột dữ liệu `latitude`, `longitude` thể hiện kinh độ, vĩ độ của các cửa hàng, `station_latitude`, `station_longitude`, `station_vincenty` và `station_great_circle` thể hiện kinh độ, vĩ độ của các trạm thời tiết, `station_vincenty`, `station_great_circle` thể hiện khoảng cách từ nhà hàng đến trạm thời tiết gần đó theo ước lượng và tính chính xác\n",
    "        - Trạng thái: các cột đều có 829 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: đều mang kiểu dữ liệu float64\n",
    "    - Với các cột `langitude_str`, `longitude_str`, `station_id`:\n",
    "        - Đây là các cột thể hiện kinh độ, vĩ độ dưới dạng string và id của trạm thời tiết gần đó\n",
    "        - Trạng thái: các cột đều có 829 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: đều mang kiểu dữ liệu object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a886b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_str</th>\n",
       "      <th>longitude_str</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197853</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197853</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197853</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197853</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>air_99c3eae84130c1cb</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air_f183a514cb8ff4fa</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air_6b9fa44a9cf504a1</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air_0919d54f0c9a24b8</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_2c6c79d597e48096</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "5  air_99c3eae84130c1cb  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "6  air_f183a514cb8ff4fa  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "7  air_6b9fa44a9cf504a1  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "8  air_0919d54f0c9a24b8  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "9  air_2c6c79d597e48096  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "    latitude   longitude  latitude_str  longitude_str  \\\n",
       "0  34.695124  135.197853  \"34.6951242\"  \"135.1978525\"   \n",
       "1  34.695124  135.197853  \"34.6951242\"  \"135.1978525\"   \n",
       "2  34.695124  135.197853  \"34.6951242\"  \"135.1978525\"   \n",
       "3  34.695124  135.197853  \"34.6951242\"  \"135.1978525\"   \n",
       "4  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "5  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "6  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "7  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "8  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "9  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "\n",
       "                   station_id  station_latitude  station_longitude  \\\n",
       "0     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "1     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "2     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "3     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "4  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "5  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "6  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "7  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "8  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "9  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "\n",
       "   station_vincenty  station_great_circle  \n",
       "0          1.277232              1.274882  \n",
       "1          1.277232              1.274882  \n",
       "2          1.277232              1.274882  \n",
       "3          1.277232              1.274882  \n",
       "4          3.730672              3.739835  \n",
       "5          3.730672              3.739835  \n",
       "6          3.730672              3.739835  \n",
       "7          3.730672              3.739835  \n",
       "8          3.730672              3.739835  \n",
       "9          3.730672              3.739835  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_store_info.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00e537",
   "metadata": {},
   "source": [
    "#### 2.1.4 `File submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83ea952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32019 entries, 0 to 32018\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        32019 non-null  object\n",
      " 1   visitors  32019 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 500.4+ KB\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137008ff",
   "metadata": {},
   "source": [
    "- File `submission` là file kết quả chúng ta sẽ nộp trên Kaggle còn được xem là file test sau này\n",
    "- Thông qua việc đọc`submission.csv`, file chứa 2 cột là `id`, `visitors`\n",
    "- Ý nghĩa của các cột dữ liệu:\n",
    "    -  Với cột dữ liệu `id`:\n",
    "        - Đây là từ khóa bao gồm id của cửa hàng + ngày có khách, thông qua từ khóa sẽ dự đoán ra số khách tương ứng\n",
    "        - Trạng thái: cột id có 32019 dòng dữ liệu, và không trống\n",
    "        - Kiểu dữ liệu: cột `id` có kiểu dữ liệu object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec5755",
   "metadata": {},
   "source": [
    "- **Ý tưởng xử lí file `submission`**:\n",
    "    - Lấy cột id của cửa hàng, ngày có khách: Thông qua str.slice() để trích xuất từ cột `id`, với 21 kí tự đầu là id của cửa hàng, từ kí tự thứ 21 trở đi là ngày có khách\n",
    "    - Đánh dấu tập test: tạo thêm 1 cột `is_test` với giá trị là True\n",
    "    - Đánh số theo index cho từng dòng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0de849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>is_test</th>\n",
       "      <th>is_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23       NaN  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24       NaN  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25       NaN  air_00a91d42b08b08d9   \n",
       "3  air_00a91d42b08b08d9_2017-04-26       NaN  air_00a91d42b08b08d9   \n",
       "4  air_00a91d42b08b08d9_2017-04-27       NaN  air_00a91d42b08b08d9   \n",
       "\n",
       "   visit_date  is_test  is_number  \n",
       "0  2017-04-23     True          0  \n",
       "1  2017-04-24     True          1  \n",
       "2  2017-04-25     True          2  \n",
       "3  2017-04-26     True          3  \n",
       "4  2017-04-27     True          4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submission['air_store_id'] = submission['id'].str.slice(0,20)\n",
    "submission['visit_date'] = submission['id'].str.slice(21)\n",
    "submission['visit_date'] = pd.to_datetime(submission['visit_date']).dt.strftime('%Y-%m-%d')\n",
    "submission['visitors'] = np.nan #để bỏ qua cột này\n",
    "submission['is_test'] = True\n",
    "submission['is_number'] = submission.index\n",
    "\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf0086",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf041a",
   "metadata": {},
   "source": [
    "#### 2.1.5 Merge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f0a54",
   "metadata": {},
   "source": [
    "Mục đích merge để có tập dữ liệu đầy đủ và hoàn thiện hơn cho mô hình\n",
    "- **Ý tưởng xử lí sau khi merge:**\n",
    "    - Thay những giá trị Nan trong cột `is_test` bằng False, giải thích về điều này là vì sau khi ghép 2 bảng lại thì những dữ liệu trong file test thì giá trị cột `is_test` là True trong khi những cột khác lại là Nan nên ta mới có cách điều chỉnh như trên\n",
    "    - Chuyển kiểu dữ liệu của cột `visitors` nhằm giữ lại các Nan là các giá trị của cột `visitors` nằm trong tập Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a44cee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>is_test</th>\n",
       "      <th>is_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_str</th>\n",
       "      <th>longitude_str</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors was_nil  is_test  is_number  \\\n",
       "0  air_00a91d42b08b08d9  2016-07-01      35.0   False    False        NaN   \n",
       "1  air_00a91d42b08b08d9  2016-07-02       9.0   False    False        NaN   \n",
       "2  air_00a91d42b08b08d9  2016-07-03       0.0    True    False        NaN   \n",
       "3  air_00a91d42b08b08d9  2016-07-04      20.0   False    False        NaN   \n",
       "4  air_00a91d42b08b08d9  2016-07-05      25.0   False    False        NaN   \n",
       "\n",
       "  day_of_week  is_holiday  prev_holiday  after_holiday  ...  \\\n",
       "0      Friday           0           0.0            0.0  ...   \n",
       "1    Saturday           0           0.0            0.0  ...   \n",
       "2      Sunday           0           0.0            0.0  ...   \n",
       "3      Monday           0           0.0            0.0  ...   \n",
       "4     Tuesday           0           0.0            0.0  ...   \n",
       "\n",
       "                     air_area_name   latitude   longitude  latitude_str  \\\n",
       "0  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "1  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "2  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "3  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "4  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "\n",
       "   longitude_str                  station_id station_latitude  \\\n",
       "0  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "1  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "2  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "3  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "4  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "\n",
       "   station_longitude  station_vincenty  station_great_circle  \n",
       "0             139.75          0.416011              0.415906  \n",
       "1             139.75          0.416011              0.415906  \n",
       "2             139.75          0.416011              0.415906  \n",
       "3             139.75          0.416011              0.415906  \n",
       "4             139.75          0.416011              0.415906  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((air_visit, submission.drop(['id'], axis = 'columns')))\n",
    "data['is_test']  = data['is_test'].fillna(False).astype('bool') #vì cột khi ép có type là object, dùng astype để chuyển sang boolean\n",
    "data = pd.merge(left = data, right = date_info, on = 'visit_date', how = 'left')\n",
    "data = pd.merge(left = data, right = air_store_info, on = 'air_store_id', how = 'left')\n",
    "data['visitors'] = data['visitors'].astype(float)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617a48c",
   "metadata": {},
   "source": [
    "## 2.2. Dữ liệu thời tiết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339b9aa",
   "metadata": {},
   "source": [
    "- **Input:** ta sẽ có dữ liệu 1663 trạm đo thời tiết\n",
    "- **Output:** ta sẽ có file dữ liệu bao gồm tất cả 1663 trạm đo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57b299b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "weather_df = []\n",
    "for path in glob.glob('weather/1-1-16_5-31-17_Weather/1-1-16_5-31-17_Weather/*.csv'):\n",
    "    weather = pd.read_csv(path)\n",
    "    weather['station_id'] = Path(path).stem\n",
    "    weather_df.append(weather)\n",
    "\n",
    "\n",
    "weather = pd.concat(weather_df, axis='rows')\n",
    "weather.rename(columns={'calendar_date': 'visit_date'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76959e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 859771 entries, 0 to 516\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   visit_date          859771 non-null  object \n",
      " 1   avg_temperature     480234 non-null  float64\n",
      " 2   high_temperature    480189 non-null  float64\n",
      " 3   low_temperature     480189 non-null  float64\n",
      " 4   precipitation       640279 non-null  float64\n",
      " 5   hours_sunlight      433473 non-null  float64\n",
      " 6   solar_radiation     24803 non-null   float64\n",
      " 7   deepest_snowfall    123827 non-null  float64\n",
      " 8   total_snowfall      120157 non-null  float64\n",
      " 9   avg_wind_speed      473007 non-null  float64\n",
      " 10  avg_vapor_pressure  80383 non-null   float64\n",
      " 11  avg_local_pressure  81048 non-null   float64\n",
      " 12  avg_humidity        80384 non-null   float64\n",
      " 13  avg_sea_pressure    78054 non-null   float64\n",
      " 14  cloud_cover         30412 non-null   float64\n",
      " 15  station_id          859771 non-null  object \n",
      "dtypes: float64(14), object(2)\n",
      "memory usage: 111.5+ MB\n"
     ]
    }
   ],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2672da5",
   "metadata": {},
   "source": [
    "- Thông qua việc đọc file tất cả các file .csv trong weather, ta thấy được có 16 cột bao gồm `visit_date`, `avg_temperature`, `high_temperature`, `low_temperature`, `precipitation`, `hours_sunlight`, `solar_radiation`, `deepest_snowfall`, `total_snowfall`, `avg_wind_speed`, `avg_vapor_pressure`, `avg_local_pressure`, `avg_humidity`, `avg_sea_pressure`, `cloud_cover` và `station_id`:\n",
    "- Nhìn qua tổng quan thì file có rất nhiều cột bị null, chỉ có cột lượng mưa `precipitation` và nhiệt độ trung bình `avg_temperature` thì ổn hơn và có vẻ dùng được\n",
    "- Giải thích vì lí do chỉ chọn lượng mưa và nhiệt độ trung bình là vì:\n",
    "    - `high_temperature` và `low_temperature` chỉ cho ta thấy được nhiệt độ cao nhất hoặc nhiệt độ thấp nhất trong ngày nhưng thứ ta cần lại là cái tổng quan hơn nên `avg_temperature` là lựa chọn hoàn hảo hơn\n",
    "    - Còn lại đa số dữ liệu thiếu quá nhiều nên không thể dùng được, chỉ có lượng mưa thì đầy đủ nhất nên chúng ta sẽ chọn lượng mưa\n",
    "- Còn về việc vì sao lại có việc dữ liệu lại thiếu nhiều như vậy, đó là bởi vì:\n",
    "    - Một số trạm sẽ đo các đặc trưng thời tiết ở một vùng nào đó, ví dụ vùng nắng nóng thì không thể nào có tuyết rơi được và ngược lại\n",
    "    - Một số trạm sẽ đo nhiều đặc trưng nhưng cũng có trạm chỉ đo một vài đặc trưng nào đó như lượng mưa, nhiệt độ\n",
    "    $\\newline$ $\\rightarrow$ Điều đó dẫn đến việc dữ liệu bị thiếu như vậy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386497d",
   "metadata": {},
   "source": [
    "### 2.2.2 Trích xuất dữ liệu thời tiết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b568663e",
   "metadata": {},
   "source": [
    "- **Một số thao tác trước khi lấy những đặc trưng cần thiết:**\n",
    "    - Tính nhiệt độ trung bình và lượng mưa trung bình theo từng ngày trên một dataframe means\n",
    "    - Ghép means với weather và thay thế các vị trí Nan bằng giá trị nhiệt độ trung bình và lượng mưa trubg bình theo từng ngày ta đã tính trước đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c85f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date  avg_temperature  precipitation\n",
       "0  2016-01-01              6.0            0.0\n",
       "1  2016-01-02              4.7            0.0\n",
       "2  2016-01-03              7.0            0.0\n",
       "3  2016-01-04              8.8            0.0\n",
       "4  2016-01-05              8.9            0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = weather.groupby('visit_date')[['avg_temperature', 'precipitation']].mean().reset_index()\n",
    "means.rename(columns={'avg_temperature': 'global_avg_temperature', 'precipitation': 'global_precipitation'}, inplace=True)\n",
    "weather = pd.merge(left=weather, right=means, on='visit_date', how='left')\n",
    "weather['avg_temperature'].fillna(weather['global_avg_temperature'], inplace=True)\n",
    "weather['precipitation'].fillna(weather['global_precipitation'], inplace=True)\n",
    "\n",
    "weather[['visit_date', 'avg_temperature', 'precipitation']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd83ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    left=data, \n",
    "    right=weather[['station_id', 'visit_date', 'avg_temperature', 'precipitation']], \n",
    "    on=['station_id', 'visit_date'], \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b19ff1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>is_test</th>\n",
       "      <th>is_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_str</th>\n",
       "      <th>longitude_str</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.70462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>29.2</td>\n",
       "      <td>7.29701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>27.8</td>\n",
       "      <td>1.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id visit_date  visitors was_nil  is_test  \\\n",
       "visit_date                                                               \n",
       "2016-07-01  air_00a91d42b08b08d9 2016-07-01      35.0   False    False   \n",
       "2016-07-02  air_00a91d42b08b08d9 2016-07-02       9.0   False    False   \n",
       "2016-07-03  air_00a91d42b08b08d9 2016-07-03       0.0    True    False   \n",
       "2016-07-04  air_00a91d42b08b08d9 2016-07-04      20.0   False    False   \n",
       "2016-07-05  air_00a91d42b08b08d9 2016-07-05      25.0   False    False   \n",
       "\n",
       "            is_number day_of_week  is_holiday  prev_holiday  after_holiday  \\\n",
       "visit_date                                                                   \n",
       "2016-07-01        NaN      Friday           0           0.0            0.0   \n",
       "2016-07-02        NaN    Saturday           0           0.0            0.0   \n",
       "2016-07-03        NaN      Sunday           0           0.0            0.0   \n",
       "2016-07-04        NaN      Monday           0           0.0            0.0   \n",
       "2016-07-05        NaN     Tuesday           0           0.0            0.0   \n",
       "\n",
       "            ...   longitude  latitude_str  longitude_str  \\\n",
       "visit_date  ...                                            \n",
       "2016-07-01  ...  139.753595  \"35.6940027\"  \"139.7535951\"   \n",
       "2016-07-02  ...  139.753595  \"35.6940027\"  \"139.7535951\"   \n",
       "2016-07-03  ...  139.753595  \"35.6940027\"  \"139.7535951\"   \n",
       "2016-07-04  ...  139.753595  \"35.6940027\"  \"139.7535951\"   \n",
       "2016-07-05  ...  139.753595  \"35.6940027\"  \"139.7535951\"   \n",
       "\n",
       "                            station_id station_latitude station_longitude  \\\n",
       "visit_date                                                                  \n",
       "2016-07-01  tokyo__tokyo-kana__tonokyo        35.691667            139.75   \n",
       "2016-07-02  tokyo__tokyo-kana__tonokyo        35.691667            139.75   \n",
       "2016-07-03  tokyo__tokyo-kana__tonokyo        35.691667            139.75   \n",
       "2016-07-04  tokyo__tokyo-kana__tonokyo        35.691667            139.75   \n",
       "2016-07-05  tokyo__tokyo-kana__tonokyo        35.691667            139.75   \n",
       "\n",
       "           station_vincenty  station_great_circle  avg_temperature  \\\n",
       "visit_date                                                           \n",
       "2016-07-01         0.416011              0.415906             25.6   \n",
       "2016-07-02         0.416011              0.415906             27.0   \n",
       "2016-07-03         0.416011              0.415906             29.2   \n",
       "2016-07-04         0.416011              0.415906             27.8   \n",
       "2016-07-05         0.416011              0.415906             21.7   \n",
       "\n",
       "            precipitation  \n",
       "visit_date                 \n",
       "2016-07-01        0.70462  \n",
       "2016-07-02        0.00000  \n",
       "2016-07-03        7.29701  \n",
       "2016-07-04        1.50000  \n",
       "2016-07-05        0.00000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['visit_date'] = pd.to_datetime(data['visit_date'])\n",
    "data = data.sort_values(['air_store_id', 'visit_date'])\n",
    "data = data.set_index('visit_date', drop=False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c771b9",
   "metadata": {},
   "source": [
    "## 2.3. Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeee68d",
   "metadata": {},
   "source": [
    "### 2.2.1 Xử lí giá trị ngoại lai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe485c",
   "metadata": {},
   "source": [
    "- **Phương pháp:** Sử dụng phương pháp Z-score với ngưỡng k = 2.4\n",
    "    - Phương pháp Z-score có công thức $Z = \\frac{x - \\bar{x}}{\\sigma}$, với Z là một giá trị thống kê kiểm tra độ lệch của từng quan sát, nếu $|Z|$ lớn hơn ngưỡng k thì quan sát đó được xem như 1 outlier\n",
    "    - Với việc tìm outlier cho cột `visitors` thì đồng nghĩa với việc tìm ra những ngày có số lượng khách tăng đột biến, có khả năng làm sai lệch quá trình học của mô hình, ví dụ như những ngày Tết, hoặc ngày lễ, ... Việc tăng cao sẽ làm cho mô hình đánh giá quá cao lượng khách trung bình và ở đây cột `visitors` không có giá trị âm nên ta chỉ cần kiểm tra Z lớn hơn ngưỡng k\n",
    "- **Việc xử lí outlier:** Sau khi tìm được outlier thì chúng ta sẽ đánh dấu theo giá trị True/False bằng cột `outlier`, sau đó sẽ tạo thêm cột `replace_visitor` để thay những giá trị outlier bằng max của giá trị không outlier\n",
    "- Và ta tạo thêm một cột `replace_visitor_log1` để lấy log transform của cột `replaced_visitors` để nhằm giảm ảnh hưởng của các giá trị quá lớn, làm cho phân phối trở nên cân bằng, hạn chế tác động của outlier. Chúng ta có thể tham khảo thêm [tại đây](https://www.geeksforgeeks.org/data-science/log-transformation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92684ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>is_test</th>\n",
       "      <th>is_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>outlier</th>\n",
       "      <th>replace_visitors</th>\n",
       "      <th>replace_visitor_log1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.70462</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.583519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>29.2</td>\n",
       "      <td>7.29701</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>27.8</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.044522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id visit_date  visitors was_nil  is_test  \\\n",
       "visit_date                                                               \n",
       "2016-07-01  air_00a91d42b08b08d9 2016-07-01      35.0   False    False   \n",
       "2016-07-02  air_00a91d42b08b08d9 2016-07-02       9.0   False    False   \n",
       "2016-07-03  air_00a91d42b08b08d9 2016-07-03       0.0    True    False   \n",
       "2016-07-04  air_00a91d42b08b08d9 2016-07-04      20.0   False    False   \n",
       "2016-07-05  air_00a91d42b08b08d9 2016-07-05      25.0   False    False   \n",
       "\n",
       "            is_number day_of_week  is_holiday  prev_holiday  after_holiday  \\\n",
       "visit_date                                                                   \n",
       "2016-07-01        NaN      Friday           0           0.0            0.0   \n",
       "2016-07-02        NaN    Saturday           0           0.0            0.0   \n",
       "2016-07-03        NaN      Sunday           0           0.0            0.0   \n",
       "2016-07-04        NaN      Monday           0           0.0            0.0   \n",
       "2016-07-05        NaN     Tuesday           0           0.0            0.0   \n",
       "\n",
       "            ...                  station_id station_latitude  \\\n",
       "visit_date  ...                                                \n",
       "2016-07-01  ...  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "2016-07-02  ...  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "2016-07-03  ...  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "2016-07-04  ...  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "2016-07-05  ...  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "\n",
       "            station_longitude  station_vincenty station_great_circle  \\\n",
       "visit_date                                                             \n",
       "2016-07-01             139.75          0.416011             0.415906   \n",
       "2016-07-02             139.75          0.416011             0.415906   \n",
       "2016-07-03             139.75          0.416011             0.415906   \n",
       "2016-07-04             139.75          0.416011             0.415906   \n",
       "2016-07-05             139.75          0.416011             0.415906   \n",
       "\n",
       "           avg_temperature precipitation  outlier  replace_visitors  \\\n",
       "visit_date                                                            \n",
       "2016-07-01            25.6       0.70462    False              35.0   \n",
       "2016-07-02            27.0       0.00000    False               9.0   \n",
       "2016-07-03            29.2       7.29701    False               0.0   \n",
       "2016-07-04            27.8       1.50000    False              20.0   \n",
       "2016-07-05            21.7       0.00000    False              25.0   \n",
       "\n",
       "            replace_visitor_log1  \n",
       "visit_date                        \n",
       "2016-07-01              3.583519  \n",
       "2016-07-02              2.302585  \n",
       "2016-07-03              0.000000  \n",
       "2016-07-04              3.044522  \n",
       "2016-07-05              3.258097  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findOutlier(data, k=2.4):\n",
    "    z = (data - data.mean()) / data.std()\n",
    "    return z > k\n",
    "\n",
    "def replace_outlier(data):\n",
    "    outlier = findOutlier(data)\n",
    "    max = data[~outlier].max()\n",
    "    data[outlier] = max\n",
    "    return data\n",
    "\n",
    "store = data.groupby('air_store_id')\n",
    "data['outlier'] = store.apply(lambda g: findOutlier(g['visitors'])).values\n",
    "data['replace_visitors'] = store.apply(lambda g: replace_outlier(g['visitors'])).values\n",
    "data['replace_visitor_log1'] = np.log1p(data['replace_visitors'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f9279",
   "metadata": {},
   "source": [
    "### 2.2.2 Trích xuất các đặc trưng khác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766677c",
   "metadata": {},
   "source": [
    "- Ở đây chúng ta sẽ lấy ra ngày cuối tuần và các ngày trong tháng, vì sao chúng ta lại trích xuất các đặc trưng này? Bởi vì nó sẽ phản ánh hành vi của khách hàng theo thời gian. Chẳng hạn như cuối tuần, khách hàng sẽ đi chơi nhiều, có nhu cầu ăn uống nhiều hơn nên số lượng khách sẽ tăng so với trong tuần, hoặc khi đầu tháng họ sẽ được nhận lương thì mức chi tiêu của họ sẽ khác cuối tháng. Vì vậy khi trích xuất đặc trưng `weekend` và `day_of_month`, mô hình sẽ học được quy luật và hành vi của khách hàng thông qua từng thời điểm trong tuần và trong tháng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbef14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['weekend'] = data['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "data['day_of_month'] = data['visit_date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c88343",
   "metadata": {},
   "source": [
    "### 2.2.3 Trọng số theo cấp số nhân cho số lượng khách hàng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeab61c",
   "metadata": {},
   "source": [
    "- EWM(Exponential Weighted Mean) là một cách tính trung bình với dữ liệu càng gần với hiện tại thì càng quan trọng, nó được biểu diễn qua công thức:\n",
    "$$\\text{EWM}_t = \\alpha x_{t-1} + (1 - \\alpha)\\text{EWM}_{t-1}$$\n",
    "- Với việc giảm dần theo hàm mũ cho thấy rằng khi dữ liệu càng về quá khứ thì dữ liệu đó không giúp gì nhiều cho dữ liệu hiện tại\n",
    "$\\newline\\rightarrow$ giúp nắm bắt được xu hướng ngắn hạn và phản ánh được hành vi gần đây của khách hàng\n",
    "- Ở đoạn code có một chỗ đó là **return data.shift().ewm(alpha = alpha, adjust = adjust).mean()**, mục đích của việc dùng shift() ở đây là để có thể tránh việc data leakage, nếu mà không có shift() thì chắc chắn mô hình sẽ biết được đáp án và thay vì dự đoán, mô hình sẽ \"học lõm\" dẫn đến hiệu suất huấn luyện cao một cách bất thường, nhưng lại suy giảm nghiêm trọng khi áp dụng ở tập validation hoặc dữ liệu tương lai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c21130",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     best \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mdifferential_evolution(func \u001b[38;5;241m=\u001b[39m f, bounds \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m eps, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m eps)])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cal_ewm(data, alpha \u001b[38;5;241m=\u001b[39m best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], adjust \u001b[38;5;241m=\u001b[39m adjust)\n\u001b[1;32m---> 12\u001b[0m group \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mair_store_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mday_of_week\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_best_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace_visitors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimize_week_visitor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39msort_index(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mair_store_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m group \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mair_store_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: find_best_alpha(g[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace_visitor_log1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1826\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1826\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1827\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1828\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1829\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1830\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1831\u001b[0m         ):\n\u001b[0;32m   1832\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1833\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1834\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1838\u001b[0m             )\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1887\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1859\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1860\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1885\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1887\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1889\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:928\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    927\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 928\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    930\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m      9\u001b[0m     best \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mdifferential_evolution(func \u001b[38;5;241m=\u001b[39m f, bounds \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m eps, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m eps)])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cal_ewm(data, alpha \u001b[38;5;241m=\u001b[39m best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], adjust \u001b[38;5;241m=\u001b[39m adjust)\n\u001b[1;32m---> 12\u001b[0m group \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mair_store_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: \u001b[43mfind_best_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace_visitors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimize_week_visitor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39msort_index(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mair_store_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m group \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mair_store_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: find_best_alpha(g[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace_visitor_log1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m, in \u001b[0;36mfind_best_alpha\u001b[1;34m(data, adjust, eps)\u001b[0m\n\u001b[0;32m      7\u001b[0m     error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((data \u001b[38;5;241m-\u001b[39m ewm_estimate)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error\n\u001b[1;32m----> 9\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cal_ewm(data, alpha \u001b[38;5;241m=\u001b[39m best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], adjust \u001b[38;5;241m=\u001b[39m adjust)\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\scipy\\_lib\\_util.py:440\u001b[0m, in \u001b[0;36m_transition_to_rng.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe NumPy global RNG was seeded by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.random.seed`. Beginning in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction will no longer use the global RNG.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m     ) \u001b[38;5;241m+\u001b[39m cmn_msg\n\u001b[0;32m    438\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:501\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[1;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, rng, callback, disp, polish, init, atol, updating, workers, constraints, x0, integrality, vectorized)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    487\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m    488\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m                                  integrality\u001b[38;5;241m=\u001b[39mintegrality,\n\u001b[0;32m    500\u001b[0m                                  vectorized\u001b[38;5;241m=\u001b[39mvectorized) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[1;32m--> 501\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:1247\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp:\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolishing solution with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolish_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1247\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDE_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolish_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mnfev\n\u001b[0;32m   1255\u001b[0m DE_result\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    739\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32md:\\ChuyenNganh\\Project\\Python\\PythonKHDL\\venv\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:417\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    415\u001b[0m f \u001b[38;5;241m=\u001b[39m array(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    416\u001b[0m g \u001b[38;5;241m=\u001b[39m zeros((n,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m--> 417\u001b[0m wa \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m iwa \u001b[38;5;241m=\u001b[39m zeros(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mn, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    419\u001b[0m task \u001b[38;5;241m=\u001b[39m zeros(\u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "def cal_ewm(data, alpha, adjust = False):\n",
    "    return data.shift().ewm(alpha = alpha, adjust = adjust).mean()\n",
    "def find_best_alpha(data, adjust = False, eps = 10e-5):\n",
    "    def f(alpha):\n",
    "        ewm_estimate = cal_ewm(data, alpha = min(max(alpha, 0), 1), adjust= adjust)\n",
    "        error = np.mean((data - ewm_estimate)**2)\n",
    "        return error\n",
    "    best = optimize.differential_evolution(func = f, bounds = [(0 + eps, 1 - eps)])\n",
    "    return cal_ewm(data, alpha = best['x'][0], adjust = adjust)\n",
    "\n",
    "group = data.groupby(['air_store_id', 'day_of_week']).apply(lambda g: find_best_alpha(g['replace_visitors']))\n",
    "data['optimize_week_visitor'] = group.sort_index(level=['air_store_id', 'visit_date']).values\n",
    "\n",
    "group = data.groupby(['air_store_id', 'day_of_week']).apply(lambda g: find_best_alpha(g['replace_visitor_log1']))\n",
    "data['optimize_week_visitor_log1'] = group.sort_index(level = ['air_store_id', 'visit_date']).values\n",
    "\n",
    "group = data.groupby(['air_store_id', 'weekend']).apply(lambda g: find_best_alpha(g['replace_visitors']))\n",
    "data['optimize_weekend_visitor']= group.sort_index(level= ['air_store_id', 'visit_date']).values\n",
    "\n",
    "group = data.groupby(['air_store_id', 'weekend']).apply(lambda g: find_best_alpha(g['replace_visitor_log1']))\n",
    "data['optimize_weekend_visitor_log1p'] = group.sort_index(level = ['air_store_id', 'visit_date']).values\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f473d",
   "metadata": {},
   "source": [
    "#### Tính các đặc trưng khác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f682d45",
   "metadata": {},
   "source": [
    "Hàm rollStatistic được sử dụng để tạo ra các đặc trưng thống kê dựa trên lịch sử số lượng khách của từng nhà hàng. Các thống kê bao gồm trung bình, độ biến động và xu hướng theo thời gian, được tính riêng cho từng bối cảnh như thứ trong tuần và cuối tuần. Việc sử dụng shift() đảm bảo rằng các đặc trưng chỉ dựa trên dữ liệu quá khứ, tránh hiện tượng data leakage. Những đặc trưng này giúp mô hình học được hành vi và quy luật của khách hàng theo thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3b4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>is_test</th>\n",
       "      <th>is_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>replace_visitor_log1_median_air_store_id</th>\n",
       "      <th>replace_visitor_log1_std_air_store_id</th>\n",
       "      <th>replace_visitor_log1_count_air_store_id</th>\n",
       "      <th>replace_visitor_log1_max_air_store_id</th>\n",
       "      <th>replace_visitor_log1_min_air_store_id</th>\n",
       "      <th>replace_visitor_log1_ewm_0.1_mean_air_store_id</th>\n",
       "      <th>replace_visitor_log1_ewm_0.25_mean_air_store_id</th>\n",
       "      <th>replace_visitor_log1_ewm_0.3_mean_air_store_id</th>\n",
       "      <th>replace_visitor_log1_ewm_0.5_mean_air_store_id</th>\n",
       "      <th>replace_visitor_log1_ewm_0.75_mean_air_store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.943052</td>\n",
       "      <td>0.905757</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.455426</td>\n",
       "      <td>3.263285</td>\n",
       "      <td>3.199239</td>\n",
       "      <td>2.943052</td>\n",
       "      <td>2.622819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.815870</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.109883</td>\n",
       "      <td>2.447464</td>\n",
       "      <td>2.239467</td>\n",
       "      <td>1.471526</td>\n",
       "      <td>0.655705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.673554</td>\n",
       "      <td>1.578354</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.103347</td>\n",
       "      <td>2.596729</td>\n",
       "      <td>2.480984</td>\n",
       "      <td>2.258024</td>\n",
       "      <td>2.447318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-27</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2017-05-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>32014.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1.221014</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003030</td>\n",
       "      <td>3.274015</td>\n",
       "      <td>3.348788</td>\n",
       "      <td>3.556916</td>\n",
       "      <td>3.641195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-28</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>32015.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1.221014</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003030</td>\n",
       "      <td>3.274015</td>\n",
       "      <td>3.348788</td>\n",
       "      <td>3.556916</td>\n",
       "      <td>3.641195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-29</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>32016.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1.221014</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003030</td>\n",
       "      <td>3.274015</td>\n",
       "      <td>3.348788</td>\n",
       "      <td>3.556916</td>\n",
       "      <td>3.641195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>32017.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1.221014</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003030</td>\n",
       "      <td>3.274015</td>\n",
       "      <td>3.348788</td>\n",
       "      <td>3.556916</td>\n",
       "      <td>3.641195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>32018.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1.221014</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003030</td>\n",
       "      <td>3.274015</td>\n",
       "      <td>3.348788</td>\n",
       "      <td>3.556916</td>\n",
       "      <td>3.641195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328298 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id visit_date  visitors was_nil  is_test  \\\n",
       "2016-07-01  air_00a91d42b08b08d9 2016-07-01      35.0   False    False   \n",
       "2016-07-02  air_00a91d42b08b08d9 2016-07-02       9.0   False    False   \n",
       "2016-07-03  air_00a91d42b08b08d9 2016-07-03       0.0    True    False   \n",
       "2016-07-04  air_00a91d42b08b08d9 2016-07-04      20.0   False    False   \n",
       "2016-07-05  air_00a91d42b08b08d9 2016-07-05      25.0   False    False   \n",
       "...                          ...        ...       ...     ...      ...   \n",
       "2017-05-27  air_fff68b929994bfbd 2017-05-27       NaN     NaN     True   \n",
       "2017-05-28  air_fff68b929994bfbd 2017-05-28       NaN     NaN     True   \n",
       "2017-05-29  air_fff68b929994bfbd 2017-05-29       NaN     NaN     True   \n",
       "2017-05-30  air_fff68b929994bfbd 2017-05-30       NaN     NaN     True   \n",
       "2017-05-31  air_fff68b929994bfbd 2017-05-31       NaN     NaN     True   \n",
       "\n",
       "            is_number day_of_week  is_holiday  prev_holiday  after_holiday  \\\n",
       "2016-07-01        NaN      Friday           0           0.0            0.0   \n",
       "2016-07-02        NaN    Saturday           0           0.0            0.0   \n",
       "2016-07-03        NaN      Sunday           0           0.0            0.0   \n",
       "2016-07-04        NaN      Monday           0           0.0            0.0   \n",
       "2016-07-05        NaN     Tuesday           0           0.0            0.0   \n",
       "...               ...         ...         ...           ...            ...   \n",
       "2017-05-27    32014.0    Saturday           0           0.0            0.0   \n",
       "2017-05-28    32015.0      Sunday           0           0.0            0.0   \n",
       "2017-05-29    32016.0      Monday           0           0.0            0.0   \n",
       "2017-05-30    32017.0     Tuesday           0           0.0            0.0   \n",
       "2017-05-31    32018.0   Wednesday           0           0.0            1.0   \n",
       "\n",
       "            ... replace_visitor_log1_median_air_store_id  \\\n",
       "2016-07-01  ...                                      NaN   \n",
       "2016-07-02  ...                                 3.583519   \n",
       "2016-07-03  ...                                 2.943052   \n",
       "2016-07-04  ...                                 2.302585   \n",
       "2016-07-05  ...                                 2.673554   \n",
       "...         ...                                      ...   \n",
       "2017-05-27  ...                                 3.401197   \n",
       "2017-05-28  ...                                 3.401197   \n",
       "2017-05-29  ...                                 3.401197   \n",
       "2017-05-30  ...                                 3.401197   \n",
       "2017-05-31  ...                                 3.401197   \n",
       "\n",
       "           replace_visitor_log1_std_air_store_id  \\\n",
       "2016-07-01                                   NaN   \n",
       "2016-07-02                                   NaN   \n",
       "2016-07-03                              0.905757   \n",
       "2016-07-04                              1.815870   \n",
       "2016-07-05                              1.578354   \n",
       "...                                          ...   \n",
       "2017-05-27                              1.221014   \n",
       "2017-05-28                              1.221014   \n",
       "2017-05-29                              1.221014   \n",
       "2017-05-30                              1.221014   \n",
       "2017-05-31                              1.221014   \n",
       "\n",
       "            replace_visitor_log1_count_air_store_id  \\\n",
       "2016-07-01                                      0.0   \n",
       "2016-07-02                                      1.0   \n",
       "2016-07-03                                      2.0   \n",
       "2016-07-04                                      3.0   \n",
       "2016-07-05                                      4.0   \n",
       "...                                             ...   \n",
       "2017-05-27                                    296.0   \n",
       "2017-05-28                                    296.0   \n",
       "2017-05-29                                    296.0   \n",
       "2017-05-30                                    296.0   \n",
       "2017-05-31                                    296.0   \n",
       "\n",
       "            replace_visitor_log1_max_air_store_id  \\\n",
       "2016-07-01                                    NaN   \n",
       "2016-07-02                               3.583519   \n",
       "2016-07-03                               3.583519   \n",
       "2016-07-04                               3.583519   \n",
       "2016-07-05                               3.583519   \n",
       "...                                           ...   \n",
       "2017-05-27                               4.077537   \n",
       "2017-05-28                               4.077537   \n",
       "2017-05-29                               4.077537   \n",
       "2017-05-30                               4.077537   \n",
       "2017-05-31                               4.077537   \n",
       "\n",
       "           replace_visitor_log1_min_air_store_id  \\\n",
       "2016-07-01                                   NaN   \n",
       "2016-07-02                              3.583519   \n",
       "2016-07-03                              2.302585   \n",
       "2016-07-04                              0.000000   \n",
       "2016-07-05                              0.000000   \n",
       "...                                          ...   \n",
       "2017-05-27                              0.000000   \n",
       "2017-05-28                              0.000000   \n",
       "2017-05-29                              0.000000   \n",
       "2017-05-30                              0.000000   \n",
       "2017-05-31                              0.000000   \n",
       "\n",
       "           replace_visitor_log1_ewm_0.1_mean_air_store_id  \\\n",
       "2016-07-01                                            NaN   \n",
       "2016-07-02                                       3.583519   \n",
       "2016-07-03                                       3.455426   \n",
       "2016-07-04                                       3.109883   \n",
       "2016-07-05                                       3.103347   \n",
       "...                                                   ...   \n",
       "2017-05-27                                       3.003030   \n",
       "2017-05-28                                       3.003030   \n",
       "2017-05-29                                       3.003030   \n",
       "2017-05-30                                       3.003030   \n",
       "2017-05-31                                       3.003030   \n",
       "\n",
       "           replace_visitor_log1_ewm_0.25_mean_air_store_id  \\\n",
       "2016-07-01                                             NaN   \n",
       "2016-07-02                                        3.583519   \n",
       "2016-07-03                                        3.263285   \n",
       "2016-07-04                                        2.447464   \n",
       "2016-07-05                                        2.596729   \n",
       "...                                                    ...   \n",
       "2017-05-27                                        3.274015   \n",
       "2017-05-28                                        3.274015   \n",
       "2017-05-29                                        3.274015   \n",
       "2017-05-30                                        3.274015   \n",
       "2017-05-31                                        3.274015   \n",
       "\n",
       "            replace_visitor_log1_ewm_0.3_mean_air_store_id  \\\n",
       "2016-07-01                                             NaN   \n",
       "2016-07-02                                        3.583519   \n",
       "2016-07-03                                        3.199239   \n",
       "2016-07-04                                        2.239467   \n",
       "2016-07-05                                        2.480984   \n",
       "...                                                    ...   \n",
       "2017-05-27                                        3.348788   \n",
       "2017-05-28                                        3.348788   \n",
       "2017-05-29                                        3.348788   \n",
       "2017-05-30                                        3.348788   \n",
       "2017-05-31                                        3.348788   \n",
       "\n",
       "            replace_visitor_log1_ewm_0.5_mean_air_store_id  \\\n",
       "2016-07-01                                             NaN   \n",
       "2016-07-02                                        3.583519   \n",
       "2016-07-03                                        2.943052   \n",
       "2016-07-04                                        1.471526   \n",
       "2016-07-05                                        2.258024   \n",
       "...                                                    ...   \n",
       "2017-05-27                                        3.556916   \n",
       "2017-05-28                                        3.556916   \n",
       "2017-05-29                                        3.556916   \n",
       "2017-05-30                                        3.556916   \n",
       "2017-05-31                                        3.556916   \n",
       "\n",
       "            replace_visitor_log1_ewm_0.75_mean_air_store_id  \n",
       "2016-07-01                                              NaN  \n",
       "2016-07-02                                         3.583519  \n",
       "2016-07-03                                         2.622819  \n",
       "2016-07-04                                         0.655705  \n",
       "2016-07-05                                         2.447318  \n",
       "...                                                     ...  \n",
       "2017-05-27                                         3.641195  \n",
       "2017-05-28                                         3.641195  \n",
       "2017-05-29                                         3.641195  \n",
       "2017-05-30                                         3.641195  \n",
       "2017-05-31                                         3.641195  \n",
       "\n",
       "[328298 rows x 98 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rollStatistic(data, col, group_by):\n",
    "    data.index.name = None\n",
    "    data.sort_values(group_by + ['visit_date'], inplace = True)\n",
    "    data_group = data.groupby(group_by, sort = False)\n",
    "    stats = {\n",
    "        'mean' : [],    #muc khach trung binh\n",
    "        'median' : [],  #xu huong on dinh\n",
    "        'std' : [],     #muc do on dinh\n",
    "        'count' : [],   #do dai lich su\n",
    "        'max' : [],     #muc dong nhat\n",
    "        'min' : []      #muc thap nhat\n",
    "    }\n",
    "    alpha_exp = [0.1, 0.25, 0.3, 0.5, 0.75]\n",
    "    stats.update({'ewm_{}_mean'.format(alpha) : [] for alpha in alpha_exp})\n",
    "    for _, group in data_group:\n",
    "        shift = group[col].shift()\n",
    "        rolling = shift.rolling(window = len(group), min_periods = 1)\n",
    "        stats['mean'].extend(rolling.mean())\n",
    "        stats['median'].extend(rolling.median())\n",
    "        stats['std'].extend(rolling.std())\n",
    "        stats['count'].extend(rolling.count())\n",
    "        stats['max'].extend(rolling.max())\n",
    "        stats['min'].extend(rolling.min())\n",
    "        for alpha in alpha_exp:\n",
    "            ewm_alpha = shift.ewm(alpha = alpha, adjust = False)\n",
    "            stats['ewm_{}_mean'.format(alpha)].extend(ewm_alpha.mean())\n",
    "    merge_name = '_&_'.join(group_by)\n",
    "    for stats_name, value in stats.items():\n",
    "        data['{}_{}_{}'.format(col, stats_name, merge_name)] = value\n",
    "\n",
    "rollStatistic(data, col = 'replace_visitors', group_by = ['air_store_id', 'day_of_week'])\n",
    "rollStatistic(data, col = 'replace_visitors', group_by = ['air_store_id', 'weekend'])\n",
    "rollStatistic(data, col = 'replace_visitors', group_by = ['air_store_id'])\n",
    "\n",
    "rollStatistic(data, col = 'replace_visitor_log1', group_by = ['air_store_id', 'day_of_week'])\n",
    "rollStatistic(data, col = 'replace_visitor_log1', group_by = ['air_store_id', 'weekend'])\n",
    "rollStatistic(data, col = 'replace_visitor_log1', group_by = ['air_store_id'])\n",
    "data.sort_values(['air_store_id', 'visit_date'])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9af11",
   "metadata": {},
   "source": [
    "Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedf2d6",
   "metadata": {},
   "source": [
    "Mã hóa dữ liệu bằng one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff55b5",
   "metadata": {},
   "source": [
    "- Vì sao chúng ta lại dùng one-hot encoding? Thực ra thì do mô hình không hiểu được chữ như Monday, Tuesday,... nhưng nếu ta mã hóa bằng số (Monday = 1, Tuesday = 2, ...) thì mô hình lại hiểu sai rằng những thứ đó là có mức thứ tự, trong đó những thứ có thứ tự cao được xử lí như một mức cao hơn dù không có quan hệ thứ bậc\n",
    "- Việc dùng one-hot encoding giúp cho các thứ trong tuần trở nên độc lập, thay vì để chúng trên cùng 1 thang số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d51146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>is_test</th>\n",
       "      <th>is_number</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>...</th>\n",
       "      <th>air_genre_name_Dining bar</th>\n",
       "      <th>air_genre_name_International cuisine</th>\n",
       "      <th>air_genre_name_Italian/French</th>\n",
       "      <th>air_genre_name_Izakaya</th>\n",
       "      <th>air_genre_name_Japanese food</th>\n",
       "      <th>air_genre_name_Karaoke/Party</th>\n",
       "      <th>air_genre_name_Okonomiyaki/Monja/Teppanyaki</th>\n",
       "      <th>air_genre_name_Other</th>\n",
       "      <th>air_genre_name_Western food</th>\n",
       "      <th>air_genre_name_Yakiniku/Korean food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id visit_date  visitors was_nil  is_test  \\\n",
       "2016-07-01  air_00a91d42b08b08d9 2016-07-01      35.0   False    False   \n",
       "2016-07-02  air_00a91d42b08b08d9 2016-07-02       9.0   False    False   \n",
       "2016-07-03  air_00a91d42b08b08d9 2016-07-03       0.0    True    False   \n",
       "2016-07-04  air_00a91d42b08b08d9 2016-07-04      20.0   False    False   \n",
       "2016-07-05  air_00a91d42b08b08d9 2016-07-05      25.0   False    False   \n",
       "\n",
       "            is_number  is_holiday  prev_holiday  after_holiday  \\\n",
       "2016-07-01        NaN           0           0.0            0.0   \n",
       "2016-07-02        NaN           0           0.0            0.0   \n",
       "2016-07-03        NaN           0           0.0            0.0   \n",
       "2016-07-04        NaN           0           0.0            0.0   \n",
       "2016-07-05        NaN           0           0.0            0.0   \n",
       "\n",
       "                              air_area_name  ...  air_genre_name_Dining bar  \\\n",
       "2016-07-01  Tōkyō-to Chiyoda-ku Kudanminami  ...                      False   \n",
       "2016-07-02  Tōkyō-to Chiyoda-ku Kudanminami  ...                      False   \n",
       "2016-07-03  Tōkyō-to Chiyoda-ku Kudanminami  ...                      False   \n",
       "2016-07-04  Tōkyō-to Chiyoda-ku Kudanminami  ...                      False   \n",
       "2016-07-05  Tōkyō-to Chiyoda-ku Kudanminami  ...                      False   \n",
       "\n",
       "            air_genre_name_International cuisine  \\\n",
       "2016-07-01                                 False   \n",
       "2016-07-02                                 False   \n",
       "2016-07-03                                 False   \n",
       "2016-07-04                                 False   \n",
       "2016-07-05                                 False   \n",
       "\n",
       "           air_genre_name_Italian/French air_genre_name_Izakaya  \\\n",
       "2016-07-01                          True                  False   \n",
       "2016-07-02                          True                  False   \n",
       "2016-07-03                          True                  False   \n",
       "2016-07-04                          True                  False   \n",
       "2016-07-05                          True                  False   \n",
       "\n",
       "           air_genre_name_Japanese food  air_genre_name_Karaoke/Party  \\\n",
       "2016-07-01                        False                         False   \n",
       "2016-07-02                        False                         False   \n",
       "2016-07-03                        False                         False   \n",
       "2016-07-04                        False                         False   \n",
       "2016-07-05                        False                         False   \n",
       "\n",
       "            air_genre_name_Okonomiyaki/Monja/Teppanyaki  air_genre_name_Other  \\\n",
       "2016-07-01                                        False                 False   \n",
       "2016-07-02                                        False                 False   \n",
       "2016-07-03                                        False                 False   \n",
       "2016-07-04                                        False                 False   \n",
       "2016-07-05                                        False                 False   \n",
       "\n",
       "            air_genre_name_Western food  air_genre_name_Yakiniku/Korean food  \n",
       "2016-07-01                        False                                False  \n",
       "2016-07-02                        False                                False  \n",
       "2016-07-03                        False                                False  \n",
       "2016-07-04                        False                                False  \n",
       "2016-07-05                        False                                False  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns=['day_of_week', 'air_genre_name'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>after_holiday</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>optimize_week_visitor</th>\n",
       "      <th>...</th>\n",
       "      <th>air_genre_name_Dining bar</th>\n",
       "      <th>air_genre_name_International cuisine</th>\n",
       "      <th>air_genre_name_Italian/French</th>\n",
       "      <th>air_genre_name_Izakaya</th>\n",
       "      <th>air_genre_name_Japanese food</th>\n",
       "      <th>air_genre_name_Karaoke/Party</th>\n",
       "      <th>air_genre_name_Okonomiyaki/Monja/Teppanyaki</th>\n",
       "      <th>air_genre_name_Other</th>\n",
       "      <th>air_genre_name_Western food</th>\n",
       "      <th>air_genre_name_Yakiniku/Korean food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>24.246640</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>19.781736</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.007692</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2.913289</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>16.033537</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>12.523343</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            is_holiday  prev_holiday  after_holiday   latitude   longitude  \\\n",
       "2017-04-23           0           0.0            0.0  35.694003  139.753595   \n",
       "2017-04-24           0           0.0            0.0  35.694003  139.753595   \n",
       "2017-04-25           0           0.0            0.0  35.694003  139.753595   \n",
       "2017-04-26           0           0.0            0.0  35.694003  139.753595   \n",
       "2017-04-27           0           0.0            0.0  35.694003  139.753595   \n",
       "\n",
       "            avg_temperature  precipitation  weekend  day_of_month  \\\n",
       "2017-04-23             13.6       0.500000        1            23   \n",
       "2017-04-24             14.5       0.400254        0            24   \n",
       "2017-04-25             16.0       2.007692        0            25   \n",
       "2017-04-26             16.9       0.000000        0            26   \n",
       "2017-04-27             14.7       3.500000        0            27   \n",
       "\n",
       "            optimize_week_visitor  ...  air_genre_name_Dining bar  \\\n",
       "2017-04-23              24.246640  ...                      False   \n",
       "2017-04-24              19.781736  ...                      False   \n",
       "2017-04-25               2.913289  ...                      False   \n",
       "2017-04-26              16.033537  ...                      False   \n",
       "2017-04-27              12.523343  ...                      False   \n",
       "\n",
       "            air_genre_name_International cuisine  \\\n",
       "2017-04-23                                 False   \n",
       "2017-04-24                                 False   \n",
       "2017-04-25                                 False   \n",
       "2017-04-26                                 False   \n",
       "2017-04-27                                 False   \n",
       "\n",
       "            air_genre_name_Italian/French  air_genre_name_Izakaya  \\\n",
       "2017-04-23                           True                   False   \n",
       "2017-04-24                           True                   False   \n",
       "2017-04-25                           True                   False   \n",
       "2017-04-26                           True                   False   \n",
       "2017-04-27                           True                   False   \n",
       "\n",
       "            air_genre_name_Japanese food  air_genre_name_Karaoke/Party  \\\n",
       "2017-04-23                         False                         False   \n",
       "2017-04-24                         False                         False   \n",
       "2017-04-25                         False                         False   \n",
       "2017-04-26                         False                         False   \n",
       "2017-04-27                         False                         False   \n",
       "\n",
       "            air_genre_name_Okonomiyaki/Monja/Teppanyaki  air_genre_name_Other  \\\n",
       "2017-04-23                                        False                 False   \n",
       "2017-04-24                                        False                 False   \n",
       "2017-04-25                                        False                 False   \n",
       "2017-04-26                                        False                 False   \n",
       "2017-04-27                                        False                 False   \n",
       "\n",
       "            air_genre_name_Western food  air_genre_name_Yakiniku/Korean food  \n",
       "2017-04-23                        False                                False  \n",
       "2017-04-24                        False                                False  \n",
       "2017-04-25                        False                                False  \n",
       "2017-04-26                        False                                False  \n",
       "2017-04-27                        False                                False  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['visitor_log1p'] = np.log1p(data['visitors'])\n",
    "train = data[(data['is_test'] == False) & (data['outlier'] == False) & (data['was_nil'] == False)]\n",
    "test = data[data['is_test'] == True].sort_values('is_number')\n",
    "#liet ke cac cot de xoa\n",
    "col_drop = ['air_store_id', 'visitors', 'is_test', 'outlier', 'visit_date', 'was_nil', 'is_number',\n",
    "            'replace_visitors', 'air_area_name', 'station_id', 'station_latitude', 'station_longitude', 'station_vincenty',\n",
    "            'station_great_circle', 'replace_visitor_log1', 'latitude_str', 'longitude_str']\n",
    "\n",
    "train = train.drop(col_drop, axis = 'columns')\n",
    "train = train.dropna()\n",
    "X_train = train.drop('visitor_log1p', axis = 'columns')\n",
    "Y_train = train['visitor_log1p']\n",
    "\n",
    "test = test.drop(col_drop, axis = 'columns')\n",
    "X_test = test.drop('visitor_log1p', axis = 'columns')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c4606",
   "metadata": {},
   "source": [
    "LightGBM + KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88473161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1: 100%|████████████████████████████████████████████████| 30000/30000 [03:19<00:00, 150.72it/s]\n",
      "Fold 2: 100%|████████████████████████████████████████████████| 30000/30000 [03:19<00:00, 150.06it/s]\n",
      "Fold 3: 100%|████████████████████████████████████████████████| 30000/30000 [03:14<00:00, 154.57it/s]\n",
      "Fold 4: 100%|████████████████████████████████████████████████| 30000/30000 [03:20<00:00, 149.33it/s]\n",
      "Fold 5: 100%|████████████████████████████████████████████████| 30000/30000 [03:18<00:00, 151.50it/s]\n",
      "Fold 6: 100%|████████████████████████████████████████████████| 30000/30000 [03:11<00:00, 156.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local RMSLE: 0.54468 (±0.00173)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- model ---\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.007,\n",
    "    n_estimators=30000,\n",
    "    min_child_samples=80,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=np.random.randint(10e6),\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "n_splits = 6\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "val_scores = [0] * n_splits\n",
    "\n",
    "sub = submission['id'].to_frame()\n",
    "sub['visitors'] = 0\n",
    "\n",
    "feature_importances = pd.DataFrame(index=X_train.columns)\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train, Y_train)):\n",
    "\n",
    "    X_fit = X_train.iloc[fit_idx]\n",
    "    y_fit = Y_train.iloc[fit_idx]\n",
    "    X_val = X_train.iloc[val_idx]\n",
    "    y_val = Y_train.iloc[val_idx]\n",
    "\n",
    "    # --- tạo progress bar ---\n",
    "    pbar = tqdm(total=model.n_estimators, desc=f'Fold {i+1}', ncols=100)\n",
    "\n",
    "    def tqdm_callback(env):\n",
    "        \"\"\"Callback cho tqdm, gọi mỗi iteration\"\"\"\n",
    "        pbar.update(1)\n",
    "\n",
    "    # train model với callback\n",
    "    model.fit(\n",
    "        X_fit,\n",
    "        y_fit,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_names=['val'],\n",
    "        eval_metric='l2',\n",
    "        feature_name=X_fit.columns.tolist(),\n",
    "        callbacks=[tqdm_callback]\n",
    "    )\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    val_scores[i] = np.sqrt(model.best_score_['val']['l2'])\n",
    "    sub['visitors'] += model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "    feature_importances[i] = model.feature_importances_\n",
    "\n",
    "# trung bình kết quả\n",
    "sub['visitors'] /= n_splits\n",
    "sub['visitors'] = np.expm1(sub['visitors'])\n",
    "\n",
    "val_mean = np.mean(val_scores)\n",
    "val_std = np.std(val_scores)\n",
    "\n",
    "print('Local RMSLE: {:.5f} (±{:.5f})'.format(val_mean, val_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submissionslgbm_{:.5f}_{:.5f}.csv'.format(val_mean, val_std), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7d1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23        15\n",
       "1  air_00a91d42b08b08d9_2017-04-24        21\n",
       "2  air_00a91d42b08b08d9_2017-04-25        25\n",
       "3  air_00a91d42b08b08d9_2017-04-26        28\n",
       "4  air_00a91d42b08b08d9_2017-04-27        26"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv('submissionslgbm_0.54543_0.00193.csv')\n",
    "csv['visitors'] = csv['visitors'].round().astype(int)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395746f5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
